{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQagpYW6F0Gh"
      },
      "outputs": [],
      "source": [
        "##First, I'll import the libraries I will need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from math import sqrt, log"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Second, I'll define the RMSLE function\n",
        "def rmsle(y_true, y_pred):\n",
        "    y_pred = np.clip(y_pred, 1e-6, None)  # clip negative values to a small positive value\n",
        "    return np.sqrt(np.mean(np.square(np.log1p(y_true) - np.log1p(y_pred))))"
      ],
      "metadata": {
        "id": "Yzw9HSzJefig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Third, I'll load in my dataset\n",
        "data = pd.read_csv('steam.csv')"
      ],
      "metadata": {
        "id": "mnNAQqXgevp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Fourth, I'll select the relevant columns for my model\n",
        "features = ['avg_players', 'tags', 'genre', 'win', 'mac', 'linux']\n",
        "target = 'price'\n",
        "X = data[features]\n",
        "y = data[target]"
      ],
      "metadata": {
        "id": "FIxMC6ZLezQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Fifth, I'll process the categorical data\n",
        "categorical_features = ['tags', 'genre']\n",
        "numeric_features = ['avg_players', 'win', 'mac', 'linux']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "\n",
        "X_preprocessed = preprocessor.fit_transform(X)"
      ],
      "metadata": {
        "id": "yq4dUk3ufEAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Sixth, I'll split my dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kufKLb6cfQLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Seventh, I'll create and train the linear regression model\n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "bb_Py3enfaIA",
        "outputId": "af77efeb-2f40-4dda-f908-bb70aa67ad1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Eigth, I'll make predictions for the evaluations\n",
        "y_pred_train = linear_regression.predict(X_train)\n",
        "y_pred_test = linear_regression.predict(X_test)"
      ],
      "metadata": {
        "id": "7I79aaXJfj-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Ninth, I'll create the evaluation metrics\n",
        "\n",
        "# Train set evaluation metrics\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "rmse_train = sqrt(mse_train)\n",
        "rmsle_train = rmsle(y_train, y_pred_train)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "\n",
        "# Test set evaluation metrics\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "rmse_test = sqrt(mse_test)\n",
        "rmsle_test = rmsle(y_test, y_pred_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "dwD9yEDzfxn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Tenth, I'll print the evaluation metrics for the train and test sets\n",
        "print(\"Train set evaluation metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_train:.2f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_train:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_train:.2f}\")\n",
        "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle_train:.2f}\")\n",
        "print(f\"R squared: {r2_train:.2f}\")\n",
        "\n",
        "print(\"\\nTest set evaluation metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_test:.2f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_test:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_test:.2f}\")\n",
        "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle_test:.2f}\")\n",
        "print(f\"R squared: {r2_test:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHrPBSZef_8W",
        "outputId": "4ab4e893-a487-4584-a120-6ea6fe491edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set evaluation metrics:\n",
            "Mean Absolute Error (MAE): 1.36\n",
            "Mean Squared Error (MSE): 3.18\n",
            "Root Mean Squared Error (RMSE): 1.78\n",
            "Root Mean Squared Logarithmic Error (RMSLE): 0.24\n",
            "R squared: 0.99\n",
            "\n",
            "Test set evaluation metrics:\n",
            "Mean Absolute Error (MAE): 1.38\n",
            "Mean Squared Error (MSE): 3.31\n",
            "Root Mean Squared Error (RMSE): 1.82\n",
            "Root Mean Squared Logarithmic Error (RMSLE): 0.25\n",
            "R squared: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Import libraries:** This chunk imports the necessary Python libraries for data manipulation, preprocessing, model creation, and evaluation.\n",
        "\n",
        "2. **Define RMSLE function:** This chunk defines a custom function to calculate the Root Mean Squared Logarithmic Error (RMSLE), which is an evaluation metric used to measure the difference between actual and predicted values in a regression problem. The function clips negative predictions to a small positive value and computes the RMSLE using the formula.\n",
        "\n",
        "3. **Load dataset:** This chunk loads the 'steam.csv' dataset into a pandas DataFrame called data. Pandas is a library used for data manipulation and analysis.\n",
        "\n",
        "4. **Select relevant columns:** This chunk selects the relevant feature columns ('avg_players', 'tags', 'genre', 'win', 'mac', 'linux') and the target column ('price') for the regression problem. It then creates a feature matrix X and target vector y.\n",
        "\n",
        "5. **Process categorical data:** This chunk preprocesses the categorical features 'tags' and 'genre' using one-hot encoding. One-hot encoding is a technique that converts categorical variables into a binary vector representation, making them suitable for use in machine learning algorithms. The ColumnTransformer is used to apply one-hot encoding to the categorical columns while keeping the numeric columns unchanged.\n",
        "\n",
        "6. **Split dataset:** This chunk splits the preprocessed dataset into training and testing sets using the train_test_split function. The training set is used to train the model, while the testing set is used to evaluate its performance.\n",
        "\n",
        "7. **Create and train the linear regression model:** This chunk creates a Linear Regression model and trains it using the training set.\n",
        "\n",
        "8. **Make predictions:** This chunk uses the trained model to make predictions on both the training and testing sets. These predictions are used to compute the evaluation metrics.\n",
        "\n",
        "9. **Create evaluation metrics:** This chunk calculates various evaluation metrics for both the training and testing sets using the actual and predicted values. The metrics include Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Root Mean Squared Logarithmic Error (RMSLE), and R-squared.\n",
        "\n",
        "10. **Print evaluation metrics:** This chunk prints the calculated evaluation metrics for both the training and testing sets, allowing you to assess the performance of the linear regression model."
      ],
      "metadata": {
        "id": "JtyXm02dh8_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## First, import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "## Second, define a custom MultiLabelBinarizerWrapper class\n",
        "class MultiLabelBinarizerWrapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, classes=None, sparse_output=False):\n",
        "        self.classes = classes\n",
        "        self.sparse_output = sparse_output\n",
        "        self.encoder = MultiLabelBinarizer(classes=self.classes, sparse_output=self.sparse_output)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.encoder.fit(X.values.ravel())\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return self.encoder.transform(X.values.ravel())\n",
        "\n",
        "## Third, load the data from CSV and preprocess it\n",
        "data = pd.read_csv('steam.csv')\n",
        "data['tags'] = data['tags'].str.split(', ')\n",
        "data['genre'] = data['genre'].str.split(', ')\n",
        "\n",
        "## Fourth, extract features and target variable\n",
        "features = ['avg_players', 'tags', 'genre', 'win', 'mac', 'linux']\n",
        "target = 'price'\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "## Fifth, process the categorical data using pipelines\n",
        "tags_pipeline = Pipeline([\n",
        "    ('encoder', MultiLabelBinarizerWrapper())\n",
        "])\n",
        "\n",
        "genre_pipeline = Pipeline([\n",
        "    ('encoder', MultiLabelBinarizerWrapper())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('tags', tags_pipeline, ['tags']),\n",
        "        ('genre', genre_pipeline, ['genre'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "## Sixth, split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "## Seventh, train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "## Eigth, get user input and preprocess it\n",
        "tags_input = input(\"Enter the tag(s) (e.g., Action, Adventure): \")\n",
        "tags_list = [t.strip() for t in tags_input.split(', ')]\n",
        "\n",
        "genre_input = input(\"Enter the genre(s) (e.g., Action, Adventure): \")\n",
        "genre_list = [g.strip() for g in genre_input.split(', ')]\n",
        "\n",
        "avg_players = float(input(\"Enter the average number of players: \"))\n",
        "windows_input = input(\"Can it be played on Windows? (0 for no, 1 for yes): \")\n",
        "windows = 1 if windows_input in ['1', 'yes'] else 0\n",
        "\n",
        "mac_input = input(\"Can it be played on Mac? (0 for no, 1 for yes): \")\n",
        "mac = 1 if mac_input in ['1', 'yes'] else 0\n",
        "\n",
        "linux_input = input(\"Can it be played on Linux? (0 for no, 1 for yes): \")\n",
        "linux = 1 if linux_input in ['1', 'yes'] else 0\n",
        "\n",
        "new_data = pd.DataFrame({'tags': [tags_list], 'genre': [genre_list], 'avg_players': [avg_players], 'win': [windows], 'mac': [mac], 'linux': [linux]})\n",
        "user_input_preprocessed = preprocessor.transform(new_data)\n",
        "\n",
        "## Ninth, make a price prediction based on the user input\n",
        "price_pred = model.predict(user_input_preprocessed)\n",
        "\n",
        "## Tenth, display the predicted price\n",
        "print(\"The predicted price is: ${:.2f}\".format(price_pred[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1ydQXTAljf0",
        "outputId": "80178a67-4ee3-4b65-d2b7-9fe56b8fac9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the tag(s) (e.g., Action, Adventure): Co-op, Multiplayer, Survival, Submarine, SurvivalHorror, 2D, Underwater, Simulation, Sci-fi, Horror, Management, Strategy, Action, Difficult, Moddable, Gore, Violent, Singleplayer, Early Access, Naval\n",
            "Enter the genre(s) (e.g., Action, Adventure): Action, Indie, Simulation, Strategy\n",
            "Enter the average number of players: 7500\n",
            "Can it be played on Windows? (0 for no, 1 for yes): 1\n",
            "Can it be played on Mac? (0 for no, 1 for yes): 0\n",
            "Can it be played on Linux? (0 for no, 1 for yes): 0\n",
            "The predicted price is: $29.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['Submarine', 'SurvivalHorror'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Import libraries:** This chunk imports the necessary Python libraries for data manipulation, preprocessing, model creation, and evaluation. These libraries include pandas for data handling, scikit-learn for machine learning algorithms and model building, and numpy for numerical operations.\n",
        "\n",
        "2. **Define custom class for encoding multiple labels:** This chunk defines a custom class called MultiLabelBinarizerWrapper that inherits from BaseEstimator and TransformerMixin. This class is a wrapper for the MultiLabelBinarizer from scikit-learn, which is used to convert multiple categorical labels into a binary matrix. This custom class will be used later in the pipeline to process the 'tags' and 'genre' features.\n",
        "\n",
        "3. **Load and preprocess data:** This chunk loads the 'steam.csv' dataset into a pandas DataFrame called data. It then splits the comma-separated 'tags' and 'genre' columns into lists of individual tags and genres, making it easier to process these categorical features later.\n",
        "\n",
        "4. **Extract features and target variable:** This chunk selects the relevant feature columns ('avg_players', 'tags', 'genre', 'win', 'mac', 'linux') and the target column ('price') for the regression problem. It then creates a feature matrix X and target vector y.\n",
        "\n",
        "5. **Process categorical data using pipelines:** This chunk creates two pipelines, one for the 'tags' column and another for the 'genre' column. Both pipelines use the custom MultiLabelBinarizerWrapper class to convert the categorical data into a binary matrix. A ColumnTransformer is used to apply these pipelines to the appropriate columns while keeping the numeric columns unchanged.\n",
        "\n",
        "6. **Split data into training and test sets:** This chunk uses the train_test_split function to split the preprocessed dataset into training and testing sets. The training set is used to train the model, while the testing set is used to evaluate its performance.\n",
        "\n",
        "7. **Train linear regression model:** This chunk creates a LinearRegression model and trains it using the training set. The trained model can then be used to make predictions on new data.\n",
        "\n",
        "8. **Get user input and preprocess it:** This chunk prompts the user to enter information about a game, such as its tags, genre, average number of players, and platform compatibility. It then creates a new DataFrame with the user input and preprocesses it using the same pipelines and ColumnTransformer used for the original dataset.\n",
        "\n",
        "9. **Make a price prediction based on user input:** This chunk uses the trained linear regression model to make a price prediction for the game with the user-provided information. This prediction is an estimate of the game's price based on the model's understanding of the relationships between the features and the target variable.\n",
        "\n",
        "10. **Display the predicted price to the user:** This chunk formats and prints the predicted price for the game, giving the user an estimate of what the game's price might be based on the input data."
      ],
      "metadata": {
        "id": "iSzbN4V5nlr1"
      }
    }
  ]
}